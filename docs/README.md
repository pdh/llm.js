# LLM.js

Run Large-Language Models (LLMs) üöÄ directly in your browser!

LLM.js provides JavaScript bindings for interacting with quantized large language models (GGUF).

Example projectsüåê‚ú®: [Live Demo](https://rahuldshetty.github.io/llm.js-examples/)

Models Supported:
-  [TinyLLaMA Series - 1,2,3ü¶ô](https://huggingface.co/TinyLlama)
-  [GPT-2](https://huggingface.co/gpt2)
-  [Tiny Mistral Series](https://huggingface.co/Locutusque/TinyMistral-248M)
-  [Tiny StarCoder Py](https://huggingface.co/bigcode/tiny_starcoder_py)
-  [Qwen Models](https://huggingface.co/Qwen)
-  [TinySolar](https://huggingface.co/upstage/TinySolar-248m-4k-code-instruct)
-  [Pythia](https://github.com/EleutherAI/pythia)
-  [Mamba](https://huggingface.co/state-spaces/mamba-130m-hf)
and much more‚ú® 

## Features

- Run inference directly on browser (even on smartphones)
- Guidance: Structure responses with CFG Grammar and JSON schema
- Developed in pure JavaScript
- Web Worker to perform background tasks (model downloading/inference)
- Model Caching support
- Pre-built [packages](https://github.com/rahuldshetty/llm.js/releases) to directly plug-and-play into your web apps.

